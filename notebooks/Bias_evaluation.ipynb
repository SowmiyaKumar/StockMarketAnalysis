{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea938d-cff5-48c6-8c58-f806c76297d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable (Price) into categories (low price, high price)\n",
    "# For example, consider prices below the median as 'Low' and above the median as 'High'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load  cleaned dataset (this is already in stock_df)\n",
    "stock_df = pd.read_csv('cleaned.csv')\n",
    "\n",
    "# Create a binary target: 0 for 'Low' Price and 1 for 'High' Price\n",
    "median_price = stock_df['Price'].median()\n",
    "stock_df['Price_Bin'] = stock_df['Price'].apply(lambda x: 1 if x > median_price else 0)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = stock_df[['US_GDP', 'US_HousingPriceIndex', 'US_INDPRO', 'US_UNRATE', 'US_CPI']]\n",
    "y = stock_df['Price_Bin']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23b2514-8c9e-40b7-96ef-39e485c62c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sensitive attribute\n",
    "# Create a binary feature for US_UNRATE (0: Low Unemployment, 1: High Unemployment)\n",
    "median_unrate = stock_df['US_UNRATE'].median()\n",
    "stock_df['Unemployment_Bin'] = stock_df['US_UNRATE'].apply(lambda x: 1 if x > median_unrate else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0432189-2cf3-46fc-8e03-4c7c81dc48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabb5d03-6928-44f0-99b4-85aed39143fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.3947402429568364\n",
      "Statistical Parity Difference: -0.43058747816493514\n",
      "Consistency: [0.93084746]\n"
     ]
    }
   ],
   "source": [
    "# Import AIF360 libraries\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Convert the dataset into AIF360 BinaryLabelDataset\n",
    "dataset = BinaryLabelDataset(\n",
    "    df=stock_df[['US_GDP', 'US_HousingPriceIndex', 'US_INDPRO', 'US_UNRATE', 'US_CPI', 'Unemployment_Bin', 'Price_Bin']],\n",
    "    label_names=['Price_Bin'],\n",
    "    protected_attribute_names=['Unemployment_Bin'],  # Sensitive attribute\n",
    "    favorable_label=1,  # 'High Price' is favorable\n",
    "    unfavorable_label=0  # 'Low Price' is unfavorable\n",
    ")\n",
    "\n",
    "# Metrics for the dataset\n",
    "metric = BinaryLabelDatasetMetric(dataset, privileged_groups=[{'Unemployment_Bin': 0}], unprivileged_groups=[{'Unemployment_Bin': 1}])\n",
    "\n",
    "# Calculate fairness metrics\n",
    "print(f\"Disparate Impact: {metric.disparate_impact()}\")\n",
    "print(f\"Statistical Parity Difference: {metric.statistical_parity_difference()}\")\n",
    "print(f\"Consistency: {metric.consistency()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b3464d-a97e-40b7-a00b-3d3e45090d19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad485e97-49d6-4341-8729-e58d9e81e49f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Disparate Impact: 0.3947**\n",
    "   - **Interpretation**: Disparate impact measures the ratio of favorable outcomes (e.g., \"High Price\") for the unprivileged group (high unemployment) to the privileged group (low unemployment).\n",
    "   - **Threshold**: A value of **1** indicates fairness, while a value below **0.8** (or 80%) suggests potential bias.\n",
    "   - **In this case**: A disparate impact of **0.39** means that the unprivileged group (high unemployment) is **39%** as likely to receive favorable outcomes compared to the privileged group. This indicates **significant bias** against the unprivileged group.\n",
    "\n",
    "2. **Statistical Parity Difference: -0.4306**\n",
    "   - **Interpretation**: Statistical parity difference measures the difference in the probability of favorable outcomes between the privileged and unprivileged groups.\n",
    "   - **Threshold**: A value close to **0** suggests fairness, while a negative value indicates the unprivileged group is less likely to receive favorable outcomes.\n",
    "   - **In this case**: A statistical parity difference of **-0.43** shows that the unprivileged group (high unemployment) is much less likely to receive favorable outcomes, further indicating bias.\n",
    "\n",
    "3. **Consistency: 0.9308**\n",
    "   - **Interpretation**: Consistency measures whether similar individuals receive similar predictions. A value close to **1** indicates that the model is consistent in its predictions.\n",
    "   - **In this case**: A consistency score of **0.93** means that the model is relatively consistent in treating similar individuals similarly, which is a positive indication.\n",
    "\n",
    "### Summary:\n",
    "- **Bias Detected**: The **disparate impact** and **statistical parity difference** values indicate significant bias against individuals in the unprivileged group (high unemployment). The unprivileged group has much lower chances of receiving favorable outcomes.\n",
    "- **Consistency**: model shows good consistency, meaning that similar data points are treated similarly. However, this consistency doesnâ€™t necessarily mean fairness, as it may be consistently biased.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Bias Mitigation**: mitigate the bias detected using techniques such as **reweighing**, **preprocessing** the data, or **post-processing** the model's predictions to ensure fairer outcomes.\n",
    "2. **Reevaluate**: After mitigation, reevaluate these fairness metrics to see if the disparate impact and statistical parity difference have improved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13ba2403-447d-4ae7-9d02-2fd02155b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact after Reweighing: 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Apply Reweighing to mitigate bias\n",
    "reweighing = Reweighing(unprivileged_groups=[{'Unemployment_Bin': 1}], privileged_groups=[{'Unemployment_Bin': 0}])\n",
    "dataset_transf = reweighing.fit_transform(dataset)\n",
    "\n",
    "# Check metrics after reweighing\n",
    "metric_transf = BinaryLabelDatasetMetric(dataset_transf, privileged_groups=[{'Unemployment_Bin': 0}], unprivileged_groups=[{'Unemployment_Bin': 1}])\n",
    "print(f\"Disparate Impact after Reweighing: {metric_transf.disparate_impact()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
